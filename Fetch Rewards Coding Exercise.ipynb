{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch Rewards Coding Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = \"The easiest way to earn points with Fetch Rewards is to just shop for the products you already love. If you have any participating brands on your receipt, you'll get points based on the cost of the products. You don't need to clip any coupons or scan individual barcodes. Just scan each grocery receipt after you shop and we'll find the savings for you.\"\n",
    "sample_2 = \"The easiest way to earn points with Fetch Rewards is to just shop for the items you already buy. If you have any eligible brands on your receipt, you will get points based on the total cost of the products. You do not need to cut out any coupons or scan individual UPCs. Just scan your receipt after you check out and we will find the savings for you.\"\n",
    "sample_3 = \"We are always looking for opportunities for you to earn more points, which is why we also give you a selection of Special Offers. These Special Offers are opportunities to earn bonus points on top of the regular points you earn every time you purchase a participating brand. No need to pre-select these offers, we'll give you the points whether or not you knew about the offer. We just think it is easier that way.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function assumes only strings with no numeric characters will be entered. Contractions are converted to their full root words and punctuation is removed by the function. The similarity metric measures how similar the texts are not only in word order, but also in vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will need this to identify the vocabulary of each sample\n",
    "def unique(list1):\n",
    "    unique_list = []\n",
    "    for x in list1:\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    return(unique_list)\n",
    "\n",
    "def similarity(sample_1, sample_2):\n",
    "    #replace contractions with full words and remove punctuation, would normally use regex for this\n",
    "    sample_1 = sample_1.replace(\"n't\", \" not\").replace(\"'ll\", \" will\").replace(\".\", \"\").replace(\",\", \"\").lower()\n",
    "    sample_2 = sample_2.replace(\"n't\", \" not\").replace(\"'ll\", \" will\").replace(\".\", \"\").replace(\",\", \"\").lower()\n",
    "    \n",
    "    #tokenize (separate into a list of individual words)\n",
    "    sample_1_tokens = sample_1.split(\" \")\n",
    "    sample_2_tokens = sample_2.split(\" \")    \n",
    "    \n",
    "    #If the two samples aren't the same length, add blank strings at the end of the shorter sample until both are equal length\n",
    "    if len(sample_1_tokens) != len(sample_2_tokens):\n",
    "        sample_1_padded = sample_1_tokens + [''] * (max([len(sample_1_tokens), len(sample_2_tokens)]) - len(sample_1_tokens))\n",
    "        sample_2_padded = sample_2_tokens + [''] * (max([len(sample_1_tokens), len(sample_2_tokens)]) - len(sample_2_tokens))\n",
    "    \n",
    "    #This portion compares if the sentences have the same word in the same position#\n",
    "    #This is why both samples need to be the same length\n",
    "    sameness = []\n",
    "    for token in range(len(sample_2_padded)):\n",
    "        if sample_1_padded[token] == sample_2_padded[token]:\n",
    "            sameness.append(1)\n",
    "        else:\n",
    "            sameness.append(0)\n",
    "            \n",
    "    #This portion check to see if the two sample use many of the same words, they just might be in a different order\n",
    "    sample_1_unique = unique(sample_1_tokens)\n",
    "    for token in range(len(sample_1_unique)):\n",
    "        if sample_1_unique[token] in unique(sample_2_tokens):\n",
    "            sameness.append(1)\n",
    "        else:\n",
    "            sameness.append(0)\n",
    "            \n",
    "    return round((sum(sameness) / len(sameness)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(sample_1, sample_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(sample_1, sample_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(sample_2, sample_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Samples 1 and 2 are so similar, it makes sense that they have similar scores when compared to Sample 3. Using vectorizers like td-idf or BERT, an even better comparison could be achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
